{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f2c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import utm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score, confusion_matrix, accuracy_score, mean_squared_error, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, TimeDistributed, Input, Activation, concatenate\n",
    "from keras.callbacks import History\n",
    "from keras.models import Model\n",
    "\n",
    "# The values have around 15 decimals, so for more clarity in reading we're increasing the number of displayed values\n",
    "pd.set_option('display.float_format', '{:.15f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd2a44b",
   "metadata": {},
   "source": [
    "# 1. Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_and_loc_file = '../data/Processed/full_sensor_data_no_interpol_and_location.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1824705f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sensor_and_loc = pd.read_csv(sensor_and_loc_file, index_col=0)\n",
    "df_sensor_and_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensor_and_loc.loc[:, 'lat'].interpolate(method='linear', inplace=True)\n",
    "df_sensor_and_loc.loc[:, 'long'].interpolate(method='linear', inplace=True)\n",
    "df_sensor_and_loc.dropna(inplace=True)\n",
    "df_sensor_and_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_sensor_and_loc.copy(deep=True)[::1]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data['long'], data['lat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd22ac3",
   "metadata": {},
   "source": [
    "# 2. Creating the LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e196ad16",
   "metadata": {},
   "source": [
    "## 2.1. Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5b0c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "backcandles=30  # number of last values to look into\n",
    "attributes_cols=12\n",
    "pca_components=3\n",
    "num_cols_to_eliminate=attributes_cols-data.shape[1]\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "attributes = data.iloc[:, :num_cols_to_eliminate]  # Assuming the target columns are the last two columns\n",
    "targets = data.iloc[backcandles:, num_cols_to_eliminate:]  # Assuming the target columns are the last two columns\n",
    "attributes.columns, targets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b3b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply PCA with 3 desired components\n",
    "pca = PCA(n_components=pca_components)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a718702",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for i in range(pca_components): #number of attributes columns\n",
    "    X.append([])\n",
    "    for j in range(backcandles, X_pca.shape[0]):\n",
    "        X[i].append(X_pca[j-backcandles:j, i])\n",
    "        \n",
    "# move axis from 0 to position 2\n",
    "X = np.moveaxis(X, [0], [2])\n",
    "\n",
    "# We need shape (8581, 30, 12) = (rows, val of past attributes, columns) for LSTM training\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(X), np.array(targets)\n",
    "\n",
    "print('X Shape: ',X.shape)\n",
    "print('y shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2984cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitlimit_test = int(len(X) * 0.7)\n",
    "splitlimit_val = int(len(X) * 0.9)\n",
    "\n",
    "print(splitlimit_test, splitlimit_val)\n",
    "X_train, X_test, X_val = X[:splitlimit_test], X[splitlimit_test:splitlimit_val], X[splitlimit_val:]\n",
    "y_train, y_test, y_val = y[:splitlimit_test], y[splitlimit_test:splitlimit_val], y[splitlimit_val:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4be035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(backcandles, pca_components)))  # 2 LSTM layers\n",
    "model.add(Dropout(0.2))  # 2 Dropout layers\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2))  # 1 Dense layer for output\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.005), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLearning(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback to plot the learning curves of the model during training.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "        \n",
    "        # Plotting\n",
    "        metrics = [x for x in logs if 'val' not in x]\n",
    "        \n",
    "        f, axs = plt.subplots(1, len(metrics), figsize=(15,5))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2), \n",
    "                        self.metrics[metric], \n",
    "                        label=metric)\n",
    "            if logs['val_' + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2), \n",
    "                            self.metrics['val_' + metric], \n",
    "                            label='val_' + metric)\n",
    "                \n",
    "            axs[i].legend()\n",
    "            axs[i].grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2920506",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "epochs=30\n",
    "\n",
    "# Train the LSTM model\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          epochs=epochs, \n",
    "          batch_size=batch_size, \n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[PlotLearning()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24727a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "for i in range(10):\n",
    "    print(y_pred[i], y_test[i])\n",
    "len(y_pred), len(y_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test[:, 1], y_test[:, 0], color='black', label='Test')\n",
    "# plt.scatter(y_pred[:, 1], y_pred[:, 0], color='blue', label='Pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6edbc12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
