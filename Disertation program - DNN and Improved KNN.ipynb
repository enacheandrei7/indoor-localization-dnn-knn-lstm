{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bdb09ba",
   "metadata": {},
   "source": [
    "# Indoor localization using deep learning with DNN and KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9015ed1d",
   "metadata": {},
   "source": [
    "## 1. Importing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8befe33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from sklearn.preprocessing import scale, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error, classification_report\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import geopy.distance\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa748e9",
   "metadata": {},
   "source": [
    "## 2. Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10c5dc",
   "metadata": {},
   "source": [
    "### 2.1. UJIIndoorLoc dataset\n",
    "* Dataset: UJIIndoorLoc (https://archive.ics.uci.edu/ml/datasets/ujiindoorloc)\n",
    "* 529 attributes and 19937 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea39f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAP001</th>\n",
       "      <th>WAP002</th>\n",
       "      <th>WAP003</th>\n",
       "      <th>WAP004</th>\n",
       "      <th>WAP005</th>\n",
       "      <th>WAP006</th>\n",
       "      <th>WAP007</th>\n",
       "      <th>WAP008</th>\n",
       "      <th>WAP009</th>\n",
       "      <th>WAP010</th>\n",
       "      <th>...</th>\n",
       "      <th>WAP520</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>FLOOR</th>\n",
       "      <th>BUILDINGID</th>\n",
       "      <th>SPACEID</th>\n",
       "      <th>RELATIVEPOSITION</th>\n",
       "      <th>USERID</th>\n",
       "      <th>PHONEID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7541.2643</td>\n",
       "      <td>4.864921e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7536.6212</td>\n",
       "      <td>4.864934e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-97</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7519.1524</td>\n",
       "      <td>4.864950e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371714095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7524.5704</td>\n",
       "      <td>4.864934e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7632.1436</td>\n",
       "      <td>4.864982e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>1369909710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
       "0     100     100     100     100     100     100     100     100     100   \n",
       "1     100     100     100     100     100     100     100     100     100   \n",
       "2     100     100     100     100     100     100     100     -97     100   \n",
       "3     100     100     100     100     100     100     100     100     100   \n",
       "4     100     100     100     100     100     100     100     100     100   \n",
       "\n",
       "   WAP010  ...  WAP520  LONGITUDE      LATITUDE  FLOOR  BUILDINGID  SPACEID  \\\n",
       "0     100  ...     100 -7541.2643  4.864921e+06      2           1      106   \n",
       "1     100  ...     100 -7536.6212  4.864934e+06      2           1      106   \n",
       "2     100  ...     100 -7519.1524  4.864950e+06      2           1      103   \n",
       "3     100  ...     100 -7524.5704  4.864934e+06      2           1      102   \n",
       "4     100  ...     100 -7632.1436  4.864982e+06      0           0      122   \n",
       "\n",
       "   RELATIVEPOSITION  USERID  PHONEID   TIMESTAMP  \n",
       "0                 2       2       23  1371713733  \n",
       "1                 2       2       23  1371713691  \n",
       "2                 2       2       23  1371714095  \n",
       "3                 2       2       23  1371713807  \n",
       "4                 2      11       13  1369909710  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UJIIndoorloc dataset\n",
    "dataset_ujloc = pd.read_csv(\"../../data_UJIndoorLoc/trainingData.csv\")\n",
    "validation_dataset_ujloc = pd.read_csv(\"../../data_UJIndoorLoc/validationData.csv\")\n",
    "dataset_ujloc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba90cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset.shape)\n",
    "# print(dataset[dataset['BUILDINGID'] == 0].shape)\n",
    "# print(dataset[dataset['BUILDINGID'] == 1].shape)\n",
    "# print(dataset[dataset['BUILDINGID'] == 2].shape)\n",
    "dataset_ujloc = dataset_ujloc[dataset_ujloc['BUILDINGID'] == 2]\n",
    "validation_dataset_ujloc = validation_dataset_ujloc[validation_dataset_ujloc['BUILDINGID'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0978b7c9",
   "metadata": {},
   "source": [
    "### 2.2. PrecisLoc dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc75e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrecisLoc dataset\n",
    "dataset_dir = \"../../data_PrecisLoc/FINAL_PRECISLOC_DATASET\"\n",
    "dataset_scen_1 = os.path.join(dataset_dir, \"Scenario_1\", \"11-05-07\")\n",
    "dataset_scen_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5647741",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(dataset_scen_1):\n",
    "    if filename.startswith(\"Sensor\"):\n",
    "        sensor_readings = filename\n",
    "    if filename.startswith(\"ground\"):\n",
    "        ground_truth = filename\n",
    "\n",
    "print(sensor_readings)\n",
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e578055",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_read_scen_1 = os.path.join(dataset_scen_1, sensor_readings)\n",
    "ground_truth_scen_1 = os.path.join(dataset_scen_1, ground_truth)\n",
    "sensor_read_scen_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e046580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the unique MAC addresses of APs\n",
    "tree = ET.parse(sensor_read_scen_1)\n",
    "\n",
    "ap_list = [] \n",
    "for r in tree.iter(tag='r'):\n",
    "    ap_list.append(r.attrib['b'])\n",
    "\n",
    "ap_set = set(ap_list)\n",
    "ap_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b31f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Sensor Readings for the scenario 1, 11-05-07\n",
    "tree = ET.parse(sensor_read_scen_1)\n",
    "\n",
    "time_data_ap_dict = {}\n",
    "\n",
    "for wr in tree.iter(tag = 'wr'):\n",
    "    time_data_ap_dict[wr.attrib['st']] = wr.iter(tag='r')\n",
    "\n",
    "# for key in time_data_dict:\n",
    "#     print(key, ': ', time_data_dict[key])\n",
    "#     for r in time_data_dict[key]:\n",
    "#         print(r.attrib)\n",
    "time_data_ap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0287cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Ground Truth for the scenario 1, 11-05-07\n",
    "tree1 = ET.parse(ground_truth_scen_1)\n",
    "\n",
    "time_location_dict = {}\n",
    "\n",
    "for position in tree1.iter(tag = 'position'):\n",
    "#     print(position.attrib['time'].split(':')[:-1])\n",
    "    time_location_dict[position.attrib['time']] = position.attrib\n",
    "time_location_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38432c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_for_df = {'lat': [],\n",
    "               'long': [],\n",
    "               'timestamp': []}\n",
    "\n",
    "for timestamp, location in time_location_dict.items():\n",
    "#     print('key: ', timestamp, ', location:', location)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d902ee6",
   "metadata": {},
   "source": [
    "## 3. Data vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f96555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the bar chart for buildings\n",
    "sns.displot(dataset_ujloc[['BUILDINGID']], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dc7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the bar chart for floors\n",
    "sns.displot(dataset_ujloc[['FLOOR']],kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a043de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scatter plot of the available data points | 14,700 m2\n",
    "markers = ('s', 'X', 'o')\n",
    "colors = ('red', 'yellow', 'lightgreen')\n",
    "cmap = ListedColormap(colors[:len(np.unique(dataset_ujloc['BUILDINGID']))])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for idx, cl in enumerate(np.unique(dataset_ujloc['BUILDINGID'])):\n",
    "        plt.scatter(x=dataset_ujloc.loc[dataset_ujloc.BUILDINGID== cl]['LATITUDE'], \n",
    "                    y=dataset_ujloc.loc[dataset_ujloc.BUILDINGID== cl]['LONGITUDE'],\n",
    "                    alpha=0.6, \n",
    "                    c=[cmap(idx)],\n",
    "                    edgecolor='black',\n",
    "                    marker=markers[idx], \n",
    "                    label=cl)\n",
    "\n",
    "plt.xlabel('Latitude')\n",
    "plt.ylabel('Longitude')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c5d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buildings 0/1 have 4 floors, building 2 has 5\n",
    "sns.countplot(x=\"FLOOR\", hue=\"BUILDINGID\", data=dataset_ujloc, orient=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5835b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "xs = dataset_ujloc['LONGITUDE']\n",
    "ys = dataset_ujloc['LATITUDE']\n",
    "zs = dataset_ujloc['FLOOR']\n",
    "ax.scatter(xs, ys, zs, alpha=0.5, s=10,marker='o')\n",
    "\n",
    "plt.title(\"Location points with respect to the floor\")\n",
    "\n",
    "plt.xlabel('Latitude')\n",
    "plt.ylabel('Longitude')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f8da6e",
   "metadata": {},
   "source": [
    "## 4. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412cfc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the unused columns\n",
    "dataset_ujloc.drop([\"SPACEID\", \"RELATIVEPOSITION\", \"USERID\", \"PHONEID\", \"TIMESTAMP\"], axis=1, inplace=True)\n",
    "validation_dataset_ujloc.drop([\"SPACEID\", \"RELATIVEPOSITION\", \"USERID\", \"PHONEID\", \"TIMESTAMP\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab41b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ujloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6bc37d",
   "metadata": {},
   "source": [
    "### 4.1. Dropping BUILDINGID for cases where we train on a single building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734c6054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the building (for scenario with only a building selected)\n",
    "# dataset_ujloc.drop([\"BUILDINGID\"], axis=1, inplace=True)\n",
    "# validation_dataset_ujloc.drop([\"BUILDINGID\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca7ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_ujloc.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f591a033",
   "metadata": {},
   "source": [
    "### 4.2. Encoding a POINT column (FLOOR+BUILDINGID) for cases of multi-building classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36179e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the output (target) column for DNN (For the case of FLOOR+Building // otherwise, just floor is enough (for only 1 building seleted))\n",
    "# dataset_ujloc['POINT'] = dataset_ujloc['FLOOR'].astype(str) + dataset_ujloc['BUILDINGID'].astype(str)\n",
    "# validation_dataset_ujloc['POINT'] = validation_dataset_ujloc['FLOOR'].astype(str) + \\\n",
    "#                                     validation_dataset_ujloc['BUILDINGID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ef707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_ujloc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095488f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the FLOOR+BUILDING (=POINT)\n",
    "# floor_build_encoder = LabelEncoder()\n",
    "# floor_build_encoder.fit(dataset_ujloc[\"POINT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc89ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# floor_build_encoder = floor_build_encoder.transform(dataset_ujloc['POINT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0844567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_point_encoded = pd.DataFrame(floor_build_encoder, columns=['POINT_ENCODED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d78b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_ujloc = pd.concat([dataset_ujloc, df_point_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913fc352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_ujloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee2f9a3",
   "metadata": {},
   "source": [
    "## ----------------------- Up until here the dataset and validation are the same -------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d77f5",
   "metadata": {},
   "source": [
    "### 4.3. Splitting the data in labels and targets for the first DNN (Step 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ce0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_ujloc.iloc[:, :520].values\n",
    "y = dataset_ujloc['FLOOR'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad09faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41f1741",
   "metadata": {},
   "source": [
    "### 4.4. Splitting the dataset into Training and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87761296",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc5182",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54b115",
   "metadata": {},
   "source": [
    "### 4.5. Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84619c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7894eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd0886",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a496027a",
   "metadata": {},
   "source": [
    "## 5. Building the first DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24865123",
   "metadata": {},
   "source": [
    "### 5.1. Initializing the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d623c210",
   "metadata": {},
   "outputs": [],
   "source": [
    " nn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc295049",
   "metadata": {},
   "source": [
    "### 5.2. Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a fully-connected layer (it automatically create the input layer)\n",
    "# num of neurons = num of features (520 APs)\n",
    "input_size = 520\n",
    "nn.add(tf.keras.layers.Dense(input_dim=input_size, units=256, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f6649a",
   "metadata": {},
   "source": [
    "### 5.3. Adding the second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1944b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a layer with 128 neurons\n",
    "nn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c90719e",
   "metadata": {},
   "source": [
    "### 5.4. Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e510126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sotmax for > 2 categories\n",
    "classes = 5\n",
    "nn.add(tf.keras.layers.Dense(units=classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7a36d",
   "metadata": {},
   "source": [
    "## 6. Training the DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae2c317",
   "metadata": {},
   "source": [
    "### 6.1. Compiling the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer = Adam ==> Stochastic Gradient Descent\n",
    "nn.compile(optimizer = 'adam',\n",
    "           loss = 'sparse_categorical_crossentropy',\n",
    "           metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222212f3",
   "metadata": {},
   "source": [
    "### 6.2. Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfe4f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.fit(X_train, y_train, batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0762c6a",
   "metadata": {},
   "source": [
    "## 7. Making predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c9926a",
   "metadata": {},
   "source": [
    "### 7.1. Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4781b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b5b2e4",
   "metadata": {},
   "source": [
    "#### 7.1.1. Transforming the encoded data back to floor number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c0b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we transform  the (1899, 5) floor array back to single value (the number of the floor)\n",
    "\n",
    "# floor_pred = []\n",
    "# floors = [i for i in range(5)]\n",
    "# for arr in y_pred:\n",
    "#     max_val = max(arr)\n",
    "#     index_max = np.where(arr == max_val)\n",
    "#     floor_pred.append(floors[index_max[0][0]])\n",
    "# floor_pred = np.array(floor_pred)\n",
    "\n",
    "floor_pred = tf.argmax(y_pred, axis=1)\n",
    "floor_pred = tf.keras.backend.eval(floor_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a5ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac60d17f",
   "metadata": {},
   "source": [
    "### 7.2. Making the confusion matrix and calculating Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70724f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, floor_pred)\n",
    "print(cm)\n",
    "accuracy = accuracy_score(y_test, floor_pred)\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399bafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, floor_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e0cfdb",
   "metadata": {},
   "source": [
    "### 7.3. Predicting with the Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a77fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = validation_dataset_ujloc.iloc[:, :520].values\n",
    "y_valid = validation_dataset_ujloc['FLOOR'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b667bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = sc.fit_transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043971f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_valid = nn.predict(X_valid)\n",
    "y_pred_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b1b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3791292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_pred_valid = tf.argmax(y_pred_valid, axis=1)\n",
    "floor_pred_valid = tf.keras.backend.eval(floor_pred_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcbaddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_pred_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f475a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_valid, floor_pred_valid)\n",
    "print(cm)\n",
    "accuracy = accuracy_score(y_valid, floor_pred_valid)\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd80248",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_valid, floor_pred_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4aa1a1",
   "metadata": {},
   "source": [
    "## 8. Building the KNN regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b79f3",
   "metadata": {},
   "source": [
    "### 8.1. Creating the second training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facb803c",
   "metadata": {},
   "source": [
    "#### 8.1.1. Selecting the cluster to which out values correspond to (the Floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "floor = 3\n",
    "# floor = floor_pred_valid[0] # TODO: verify how can we change this so it gets the floor by default\n",
    "mask = dataset_ujloc['FLOOR'] == floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2b892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ap = dataset_ujloc.iloc[:, :520][mask]\n",
    "df_floor = dataset_ujloc['FLOOR'][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_step_2 = pd.concat([df_ap, df_floor], axis=1).values\n",
    "y_step_2 = dataset_ujloc[['LONGITUDE', 'LATITUDE']][mask].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0875fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_step_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375bf7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_step_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2ed717",
   "metadata": {},
   "source": [
    "### 8.3. Splitting the data in Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d6964",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_step_2, X_test_step_2, y_train_step_2, y_test_step_2 = train_test_split(X_step_2,\n",
    "                                                                                y_step_2, \n",
    "                                                                                test_size = 0.2, \n",
    "                                                                                random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_step_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084d5a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_step_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad923b1",
   "metadata": {},
   "source": [
    "### 8.4. Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_regressor = KNeighborsRegressor(n_neighbors=3, weights='distance')\n",
    "knn_regressor.fit(X_train_step_2, y_train_step_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b746f",
   "metadata": {},
   "source": [
    "### 8.5. Making predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803eb6b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_step_2 = knn_regressor.predict(X_test_step_2)\n",
    "y_pred_step_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec09a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_step_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f018bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_step_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea2d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(y_test_step_2, y_pred_step_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14135ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(y_test_step_2, y_pred_step_2, multioutput='raw_values'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395ecea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_step_2 = pd.DataFrame(y_pred_step_2, columns=['long1', 'lat1'])\n",
    "y_test_step_2 = pd.DataFrame(y_test_step_2, columns=['long2', 'lat2'])\n",
    "# alculating the Euclidian distance between points\n",
    "distance_df = pd.DataFrame((y_test_step_2['lat2']-y_pred_step_2['lat1'])**2 + \n",
    "                           (y_test_step_2['long2']-y_pred_step_2['long1'])**2)**(1/2)\n",
    "sum_dist = distance_df.sum()\n",
    "mean_error = sum_dist/len(distance_df)\n",
    "mean_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e90053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "# # Approximate radius of earth in km\n",
    "# R = 6373.0\n",
    "\n",
    "# def calc_dist(lat1, lon1, lat2, lon2):\n",
    "#     lat1 = radians(lat1)\n",
    "#     lon1 = radians(lon1)\n",
    "#     lat2 = radians(lat2)\n",
    "#     lon2 = radians(lon2)\n",
    "\n",
    "#     dlon = lon2 - lon1\n",
    "#     dlat = lat2 - lat1\n",
    "\n",
    "#     a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "#     c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "#     distance = R * c\n",
    "#     return distance\n",
    "\n",
    "# print(\"Result: \", distance)\n",
    "# print(\"Should be: \", 278.546, \"km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08436942",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame()\n",
    "df_final = pd.concat([y_pred_step_2, y_test_step_2], axis=1)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10067bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# earth_radius=6371\n",
    "\n",
    "# df_final['long1'] = np.radians(df_final['long1'])\n",
    "# df_final['long2'] = np.radians(df_final['long2'])\n",
    "# df_final['lat1'] = np.radians(df_final['lat1'])\n",
    "# df_final['lat2'] = np.radians(df_final['lat2'])\n",
    "\n",
    "\n",
    "# df_final['a'] = np.sin((df_final['lat2']-df_final['lat1'])/2.0)**2 + \\\n",
    "#     np.cos(df_final['lat1']) * np.cos(df_final['lat2']) * np.sin((df_final['long2']-df_final['long1'])/2.0)**2\n",
    "\n",
    "# df_final['DISTANCE'] = earth_radius * 2 * np.arcsin(np.sqrt(df_final['a']))\n",
    "# dist_km = df_final['DISTANCE'].sum().mean()\n",
    "# dist_m = dist_km\n",
    "# dist_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53105fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(df_final['lat1'], df_final['long1'], color='red')\n",
    "plt.scatter(df_final['lat2'], df_final['long2'], color='green', alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9590bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09288e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
